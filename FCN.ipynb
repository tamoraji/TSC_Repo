{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pip install tensorflow==2.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge cudatoolkit=11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 17:32:17.469860: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.10.0\n",
      "Keras Version: 2.10.0\n",
      "\n",
      "Python 3.9.6 (v3.9.6:db3ff76da1, Jun 28 2021, 11:49:53) \n",
      "[Clang 6.0 (clang-600.0.57)]\n",
      "Pandas 1.5.0\n",
      "Scikit-Learn 1.1.2\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670796275067,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "WI3EYR_be7ov"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670796275068,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "nYPPgDj2e7oy",
    "outputId": "c71b2a21-7bf6-46ac-c958-794ccd9e5531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53785, 749, 3)\n",
      "(53785, 749, 1)\n"
     ]
    }
   ],
   "source": [
    "# define a list of datasets\n",
    "datasets = [\"PHM2022_Multivar\", \"PHM2022_Univar_PDIN\"]\n",
    "datasets_path = \"../datasets\"\n",
    "\n",
    "for dataset in datasets:\n",
    "    Dataset_name = dataset + \"_Dataset\"\n",
    "    Dataset = np.load(datasets_path + \"/\" + Dataset_name + \".npy\")\n",
    "    print(Dataset.shape)\n",
    "    \n",
    "\n",
    "    Labels_name = dataset + \"_Labels\"\n",
    "    Labels = np.load(datasets_path + \"/\"  + Labels_name + \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The dataset shape is:(53785, 749, 3)\n",
      "\n",
      " The number of data samples (N) is:53785\n",
      "\n",
      " The number of TS length (T) is:749\n",
      "\n",
      " The number of TS dimention (M) is:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 17:52:36.528662: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 749, 3)]          0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 749, 128)          3200      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 749, 128)         512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 749, 128)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 749, 256)          164096    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 749, 256)         1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 749, 256)          0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 749, 128)          98432     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 749, 128)         512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 749, 128)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269,324\n",
      "Trainable params: 268,300\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "  31/2690 [..............................] - ETA: 8:50 - loss: 2.2070 - accuracy: 0.3145"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mojtabaaskarzadeh/TSC_Repo/FCN.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mojtabaaskarzadeh/TSC_Repo/FCN.ipynb#W6sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m classifier \u001b[39m=\u001b[39m fcn\u001b[39m.\u001b[39mClassifier_FCN(output_directory\u001b[39m=\u001b[39mresults_path, input_shape\u001b[39m=\u001b[39minput_shape,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mojtabaaskarzadeh/TSC_Repo/FCN.ipynb#W6sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m                                 nb_classes\u001b[39m=\u001b[39mnb_classes, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mojtabaaskarzadeh/TSC_Repo/FCN.ipynb#W6sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m# fit the algorithm on the training data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mojtabaaskarzadeh/TSC_Repo/FCN.ipynb#W6sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(X_train, y_train, X_test, y_test, y_true)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mojtabaaskarzadeh/TSC_Repo/FCN.ipynb#W6sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# calculate the evaluation metrics\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mojtabaaskarzadeh/TSC_Repo/FCN.ipynb#W6sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/TSC_Repo/dl4tsc/classifiers/fcn.py:72\u001b[0m, in \u001b[0;36mClassifier_FCN.fit\u001b[0;34m(self, x_train, y_train, x_val, y_val, y_true)\u001b[0m\n\u001b[1;32m     68\u001b[0m mini_batch_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mmin\u001b[39m(x_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m, batch_size))\n\u001b[1;32m     70\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \n\u001b[0;32m---> 72\u001b[0m hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(x_train, y_train, batch_size\u001b[39m=\u001b[39;49mmini_batch_size, epochs\u001b[39m=\u001b[39;49mnb_epochs,\n\u001b[1;32m     73\u001b[0m \tverbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, validation_data\u001b[39m=\u001b[39;49m(x_val,y_val), callbacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks)\n\u001b[1;32m     75\u001b[0m duration \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m     77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msave(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_directory\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlast_model.hdf5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# change this directory for your machine\n",
    "root_dir = './'\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# perform cross-validation for each dataset and algorithm combination\n",
    "for dataset in datasets:\n",
    "    Dataset_name = dataset + \"_Dataset\"\n",
    "    Dataset = np.load(datasets_path + \"/\" + Dataset_name + \".npy\")\n",
    "    \n",
    "\n",
    "    Labels_name = dataset + \"_Labels\"\n",
    "    Labels = np.load(datasets_path + \"/\"  + Labels_name + \".npy\")\n",
    "    \n",
    "\n",
    "\n",
    "    # Create a folder for results\n",
    "    results_path = root_dir + \"Results/\" + Dataset_name\n",
    "    if os.path.exists(results_path):\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            os.makedirs(results_path)\n",
    "        except:\n",
    "            # in case another machine created the path meanwhile !:(\n",
    "            pass\n",
    "\n",
    "        \n",
    "    t_total = time.time() ##Start timing\n",
    "    \n",
    "\n",
    "\n",
    "    print(f\"\\n The dataset shape is:{Dataset.shape}\")\n",
    "    print(f\"\\n The number of data samples (N) is:{Dataset.shape[0]}\")\n",
    "    print(f\"\\n The number of TS length (T) is:{Dataset.shape[1]}\")\n",
    "    print(f\"\\n The number of TS dimention (M) is:{Dataset.shape[2]}\")\n",
    "\n",
    "    nb_classes = len(np.unique(Labels, axis=0))\n",
    "    \n",
    "    # transform the labels from integers to one hot vectors\n",
    "    enc = sklearn.preprocessing.OneHotEncoder(categories='auto')\n",
    "    Labels = enc.fit_transform(Labels.reshape(-1, 1)).toarray()\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    report_list = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(Dataset)):\n",
    "        # split the data into training and testing sets\n",
    "        X_train, X_test = Dataset[train_idx], Dataset[test_idx]\n",
    "        y_train, y_test = Labels[train_idx], Labels[test_idx]\n",
    "        \n",
    "        # save orignal y because later we will use binary\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "        \n",
    "        input_shape = X_train.shape[1:]\n",
    "        \n",
    "        ## Create Classification module\n",
    "        from dl4tsc.classifiers import fcn\n",
    "        classifier = fcn.Classifier_FCN(output_directory=results_path, input_shape=input_shape,\n",
    "                                        nb_classes=nb_classes, verbose=True)\n",
    "        \n",
    "        # fit the algorithm on the training data\n",
    "        classifier.fit(X_train, y_train, X_test, y_test, y_true)\n",
    "            \n",
    "        # calculate the evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(accuracy)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(f1)\n",
    "\n",
    "        confusion = confusion_matrix(y_test, y_pred)\n",
    "        print(confusion)\n",
    "\n",
    "        accuracy_scores.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        confusion_matrices.append(confusion)\n",
    "\n",
    "        report = classification_report(y_test, y_pred, zero_division=1)\n",
    "        report_list.append(report)\n",
    "        print(report)\n",
    "        \n",
    "        print(f\" fold {fold+1} is Finished!\")\n",
    "        \n",
    "        # save the output to a text file\n",
    "        with open(f'{results_path}/dataset_{dataset_name}_FCN_fold_{fold+1}.txt', 'w') as f:\n",
    "            f.write(f'Accuracy: {accuracy}\\n')\n",
    "            f.write(f'F1 Score: {f1}\\n')\n",
    "            f.write(f'Confusion Matrix:\\n{confusion}\\n\\n')\n",
    "            f.write(f'Classification report:\\n{report}\\n\\n')\n",
    "        \n",
    "    with open(f'{results_path}/dataset_{dataset_name}_FCN.txt', 'w') as f:\n",
    "        f.write(\"Mean accuracy: {:.3f} (std={:.3f})\\n\".format(np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "        f.write(\"Mean F1 score: {:.3f} (std={:.3f})\\n\".format(np.mean(f1_scores), np.std(f1_scores)))\n",
    "        f.write(\"Mean confusion matrix:\\n{}\\n\".format(np.array2string(np.mean(confusion_matrices, axis=0))))\n",
    "        f.write(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "    print(\" Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1670797391439,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "o0hfsmobe7o6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, duration, y_true_val=None, y_pred_val=None):\n",
    "    res = pd.DataFrame(data=np.zeros((1, 4), dtype=np.float), index=[0],\n",
    "                       columns=['precision', 'accuracy', 'recall', 'duration'])\n",
    "    res['precision'] = precision_score(y_true, y_pred, average='macro')\n",
    "    res['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    if not y_true_val is None:\n",
    "        # this is useful when transfer learning is used with cross validation\n",
    "        res['accuracy_val'] = accuracy_score(y_true_val, y_pred_val)\n",
    "\n",
    "    res['recall'] = recall_score(y_true, y_pred, average='macro')\n",
    "    res['duration'] = duration\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_metrics \u001b[38;5;241m=\u001b[39m calculate_metrics(\u001b[43my_true\u001b[49m, y_pred, \u001b[38;5;241m0.0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "df_metrics = calculate_metrics(y_true, y_pred, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99
    },
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1670797392656,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "BIeCbOs6e7o6",
    "outputId": "973650ee-67f0-43ae-cf19-3b4bf69641fc"
   },
   "outputs": [],
   "source": [
    "classifier.predict(X_test, y_true,X_train,y_train,y_test,return_df_metrics = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File('./Results/PHM2022_Multivar_Datasetbest_model.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_weights', 'optimizer_weights']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
