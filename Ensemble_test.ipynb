{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4e4cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf1f216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 1000, 3)\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "\"CWRU_12k_FE_multivar\"\n",
    "]\n",
    "\n",
    "datasets_path = \"../datasets\"\n",
    "\n",
    "for dataset in datasets:\n",
    "    Dataset_name = dataset + \"_Dataset\"\n",
    "    Dataset = np.load(datasets_path + \"/\" + Dataset_name + \".npy\")\n",
    "    Dataset = Dataset\n",
    "    print(Dataset.shape)\n",
    "    \n",
    "    Labels_name = dataset + \"_Labels\"\n",
    "    Labels = np.load(datasets_path + \"/\"  + Labels_name + \".npy\")\n",
    "    Labels = Labels.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4989350f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test sizes: 2646 1134 1620\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(Dataset, Labels, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(X_train, y_train, test_size=0.3, random_state=1)\n",
    "\n",
    "print('Train/Valid/Test sizes:', y_train.shape[0], y_val.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4956ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "def train_and_evaluate_classifiers(X_train, y_train, X_val, y_val, X_test, y_test, num_classifiers):\n",
    "    classifiers = []\n",
    "    labels = []\n",
    "    train_data = []\n",
    "\n",
    "    # Create individual classifiers and add them to the ensemble\n",
    "    for i in range(num_classifiers):\n",
    "        print(i)\n",
    "        clf = KNeighborsTimeSeriesClassifier(distance=\"euclidean\", n_jobs=10)\n",
    "        classifiers.append(clf)\n",
    "        labels.append(f'Classifier {i+1}')\n",
    "        train_data.append((X_train[:,:,i], y_train))\n",
    "\n",
    "\n",
    "    # Train and evaluate classifiers\n",
    "    for clf, label, data in zip(classifiers, labels, train_data):\n",
    "        X_train_part, y_train_part = data\n",
    "        clf.fit(X_train_part, y_train_part)\n",
    "        print(\"Validation Accuracy: %0.2f [%s]\" % (clf.score(X_val, y_val), label))\n",
    "        \n",
    "    # Add ensemble classifier\n",
    "    eclf = EnsembleVoteClassifier(clfs=classifiers, voting='soft', weights=[1] * len(classifiers)) # Modified this line\n",
    "\n",
    "    # Fit the ensemble classifier with training data\n",
    "    eclf.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate and print the test accuracy\n",
    "    print(\"Test Accuracy: %0.2f\" % eclf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f77025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "num_classifiers = Dataset.shape[2]\n",
    "print(num_classifiers)# Set the desired number of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6f4a9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "Validation Accuracy: 0.12 [Classifier 1]\n",
      "Validation Accuracy: 0.14 [Classifier 2]\n",
      "Validation Accuracy: 0.14 [Classifier 3]\n",
      "Test Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_classifiers(X_train, y_train, X_val, y_val, X_test, y_test, num_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f26d8b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53785, 749, 3)\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "# \"Gas_sensors_home_activity\",\n",
    "\"PHM2022_Multivar\",\n",
    "\n",
    "]\n",
    "\n",
    "datasets_path = \"../datasets\"\n",
    "\n",
    "for dataset in datasets:\n",
    "    Dataset_name = dataset + \"_Dataset\"\n",
    "    Dataset = np.load(datasets_path + \"/\" + Dataset_name + \".npy\")\n",
    "    Dataset = Dataset\n",
    "    print(Dataset.shape)\n",
    "    \n",
    "    Labels_name = dataset + \"_Labels\"\n",
    "    Labels = np.load(datasets_path + \"/\"  + Labels_name + \".npy\")\n",
    "    Labels = Labels.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a16ae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "num_classifiers = Dataset.shape[2]\n",
    "print(num_classifiers)# Set the desired number of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eedb6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test sizes: 26354 11295 16136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(Dataset, Labels, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(X_train, y_train, test_size=0.3, random_state=1)\n",
    "\n",
    "print('Train/Valid/Test sizes:', y_train.shape[0], y_val.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa02f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "Validation Accuracy: 0.11 [Classifier 1]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_classifiers(X_train, y_train, X_val, y_val, X_test, y_test, num_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e28cb4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c917b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import EnsembleVoteClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e5b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "\n",
    "clf1 = KNeighborsTimeSeriesClassifier(distance= \"euclidean\", n_jobs=10)\n",
    "clf2 = KNeighborsTimeSeriesClassifier(distance= \"euclidean\", n_jobs=10)\n",
    "clf3 = KNeighborsTimeSeriesClassifier(distance= \"euclidean\", n_jobs=10)\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[1, 1, 1])\n",
    "\n",
    "labels = ['Classifier 1', 'Classifier 2', 'Classifier 3', 'Ensemble']\n",
    "\n",
    "# Split the training data into three subsets\n",
    "X_train1, X_train2, X_train3 = X_train[:,:,0], X_train[:,:,1], X_train[:,:,2]\n",
    "\n",
    "classifiers = [clf1, clf2, clf3, eclf]\n",
    "train_data = [(X_train1, y_train), (X_train2, y_train), (X_train3, y_train)]\n",
    "\n",
    "for clf, label, data in zip(classifiers, labels, train_data):\n",
    "    X_train_part, y_train_part = data\n",
    "    clf.fit(X_train_part, y_train_part)\n",
    "    print(\"Validation Accuracy: %0.2f [%s]\" % (clf.score(X_val, y_val), label))\n",
    "    \n",
    "eclf.fit(X_train, y_train)\n",
    "print(\"Test Accuracy: %0.2f\" % eclf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "\n",
    "clf1 = KNeighborsTimeSeriesClassifier(distance= \"euclidean\", n_jobs=10)\n",
    "clf2 = KNeighborsTimeSeriesClassifier(distance= \"euclidean\", n_jobs=10)\n",
    "clf3 = KNeighborsTimeSeriesClassifier(distance= \"euclidean\", n_jobs=10)\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='soft', weights=[1, 1, 1])\n",
    "\n",
    "labels = ['Classifier 1', 'Classifier 2', 'Classifier 3', 'Ensemble']\n",
    "\n",
    "# Split the training data into three subsets\n",
    "X_train1, X_train2, X_train3 = X_train[:,:,0], X_train[:,:,1], X_train[:,:,2]\n",
    "\n",
    "classifiers = [clf1, clf2, clf3, eclf]\n",
    "train_data = [(X_train1, y_train), (X_train2, y_train), (X_train3, y_train)]\n",
    "\n",
    "for clf, label, data in zip(classifiers, labels, train_data):\n",
    "    X_train_part, y_train_part = data\n",
    "    clf.fit(X_train_part, y_train_part)\n",
    "    print(\"Validation Accuracy: %0.2f [%s]\" % (clf.score(X_val, y_val), label))\n",
    "    \n",
    "eclf.fit(X_train, y_train)\n",
    "print(\"Test Accuracy: %0.2f\" % eclf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90044077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(Dataset, Labels, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print('Train/Valid/Test sizes:', y_train.shape[0], y_val.shape[0], y_test.shape[0])\n",
    "print(X_train.shape)\n",
    "print(Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ecaaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "def train_and_evaluate_classifiers(X_train, y_train, X_val, y_val, X_test, y_test, num_classifiers):\n",
    "    classifiers = []\n",
    "    labels = []\n",
    "    train_data = []\n",
    "\n",
    "    # Create individual classifiers and add them to the ensemble\n",
    "    for i in range(num_classifiers):\n",
    "        print(i)\n",
    "        clf = KNeighborsTimeSeriesClassifier(distance=\"euclidean\", n_jobs=10)\n",
    "        classifiers.append(clf)\n",
    "        labels.append(f'Classifier {i+1}')\n",
    "        train_data.append((X_train[:,:,i], y_train))\n",
    "\n",
    "    # Add ensemble classifier\n",
    "    eclf = EnsembleVoteClassifier(clfs=classifiers, voting='soft', weights=[1] * num_classifiers)\n",
    "    classifiers.append(eclf)\n",
    "    labels.append('Ensemble')\n",
    "    train_data.append((X_train, y_train))\n",
    "\n",
    "    # Train and evaluate classifiers\n",
    "    for clf, label, data in zip(classifiers, labels, train_data):\n",
    "        X_train_part, y_train_part = data\n",
    "        clf.fit(X_train_part, y_train_part)\n",
    "        print(\"Validation Accuracy: %0.2f [%s]\" % (clf.score(X_val, y_val), label))\n",
    "\n",
    "    # Fit the ensemble classifier with training data\n",
    "    eclf.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate and print the test accuracy\n",
    "    print(\"Test Accuracy: %0.2f\" % eclf.score(X_test, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_classifiers(X_train, y_train, X_val, y_val, X_test, y_test, num_classifiers):\n",
    "    classifiers = []\n",
    "    labels = []\n",
    "    train_data = []\n",
    "\n",
    "    # Create individual classifiers and add them to the ensemble\n",
    "    for i in range(num_classifiers):\n",
    "        print(i)\n",
    "        clf = KNeighborsTimeSeriesClassifier(distance=\"euclidean\", n_jobs=10)\n",
    "        classifiers.append(clf)\n",
    "        labels.append(f'Classifier {i+1}')\n",
    "        train_data.append((X_train[:,:,i], y_train))\n",
    "\n",
    "    # Add ensemble classifier\n",
    "    eclf = EnsembleVoteClassifier(clfs=classifiers, voting='soft', weights=[1] * len(classifiers)) # Modified this line\n",
    "    classifiers.append(eclf)\n",
    "    labels.append('Ensemble')\n",
    "    train_data.append((X_train, y_train))\n",
    "\n",
    "    # Train and evaluate classifiers\n",
    "    for clf, label, data in zip(classifiers, labels, train_data):\n",
    "        X_train_part, y_train_part = data\n",
    "        clf.fit(X_train_part, y_train_part)\n",
    "        print(\"Validation Accuracy: %0.2f [%s]\" % (clf.score(X_val, y_val), label))\n",
    "\n",
    "    # Fit the ensemble classifier with training data\n",
    "    eclf.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate and print the test accuracy\n",
    "    print(\"Test Accuracy: %0.2f\" % eclf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e43980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "num_classifiers = Dataset.shape[2]\n",
    "print(num_classifiers)# Set the desired number of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d6815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_classifiers(X_train, y_train, X_val, y_val, X_test, y_test, num_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1440f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n The dataset shape is:{Dataset.shape}\")\n",
    "N=Dataset.shape[0]\n",
    "print(f\"\\n The number of data samples (N) is:{N}\")\n",
    "\n",
    "T=Dataset.shape[1]\n",
    "print(f\"\\n The number of TS length (T) is:{T}\")\n",
    "\n",
    "M=Dataset.shape[2]\n",
    "print(f\"\\n The number of TS dimention (M) is:{M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a263e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split the multivariate time-series into separate univariate time-series, one for each variable\n",
    "X_univariate = np.split(Dataset, M, axis=2)\n",
    "len(X_univariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aa3e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_univariate[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d49708",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset[:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store predicted class labels for each univariate time-series\n",
    "y_pred_univariate = []\n",
    "\n",
    "# perform KNN classification on each univariate time-series independently\n",
    "for X_var in X_univariate:\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_var.reshape(N, T), Labels.squeeze(), test_size=0.2, shuffle=True)\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    # KNN classification\n",
    "    from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "    classifier = KNeighborsTimeSeriesClassifier(distance= \"euclidean\", n_jobs=10)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "        \n",
    "    # predict class labels\n",
    "    y_pred_var = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred_var)\n",
    "    print(f\"accuracy for dimension:{accuracy}\")\n",
    "    y_pred_univariate.append(y_pred_var)\n",
    "    print(len(y_pred_univariate))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59534235",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94349eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077db891",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_univariate[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d12eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble the results by taking the majority vote for each time step\n",
    "#y_pred_ensemble = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=0, arr=y_pred_univariate)\n",
    "y_pred_ensemble = np.apply_along_axis(lambda x: np.argmax(np.bincount(np.round(x).astype(int))), axis=0, arr=y_pred_univariate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bea78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the accuracy of the final classification\n",
    "accuracy = accuracy_score(y_test, y_pred_ensemble)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_ensemble, average='weighted')\n",
    "print(f1)\n",
    "\n",
    "print(\"Accuracy of KNN classification on multivariate time-series:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee8d889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
