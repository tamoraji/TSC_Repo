{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670796275067,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "WI3EYR_be7ov"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670796275068,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "nYPPgDj2e7oy",
    "outputId": "c71b2a21-7bf6-46ac-c958-794ccd9e5531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53785, 749, 3)\n",
      "(53785, 749, 1)\n"
     ]
    }
   ],
   "source": [
    "# define a list of datasets\n",
    "datasets = [\"PHM2022_Multivar\", \"PHM2022_Univar_PDIN\"]\n",
    "datasets_path = \"../datasets\"\n",
    "\n",
    "for dataset in datasets:\n",
    "    Dataset_name = dataset + \"_Dataset\"\n",
    "    Dataset = np.load(datasets_path + \"/\" + Dataset_name + \".npy\")\n",
    "    print(Dataset.shape)\n",
    "    \n",
    "\n",
    "    Labels_name = dataset + \"_Labels\"\n",
    "    Labels = np.load(datasets_path + \"/\"  + Labels_name + \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The dataset shape is:(53785, 749, 3)\n",
      "\n",
      " The number of data samples (N) is:53785\n",
      "\n",
      " The number of TS length (T) is:749\n",
      "\n",
      " The number of TS dimention (M) is:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 12:09:00.712812: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-28 12:09:01.118602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 749, 3)]          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2247)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2247)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               1124000   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 12)                6012      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,631,012\n",
      "Trainable params: 1,631,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 12:09:01.944399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-03-28 12:09:01.944592: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-03-28 12:09:01.958056: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 2.1436 - accuracy: 0.3291 - val_loss: 1.6691 - val_accuracy: 0.4503 - lr: 0.0010\n",
      "Epoch 2/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 1.7606 - accuracy: 0.4237 - val_loss: 1.4542 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 3/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 1.5962 - accuracy: 0.4615 - val_loss: 1.3347 - val_accuracy: 0.5562 - lr: 0.0010\n",
      "Epoch 4/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 1.4875 - accuracy: 0.4906 - val_loss: 1.2494 - val_accuracy: 0.5988 - lr: 0.0010\n",
      "Epoch 5/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 1.4161 - accuracy: 0.5097 - val_loss: 1.1819 - val_accuracy: 0.6291 - lr: 0.0010\n",
      "Epoch 6/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 1.3534 - accuracy: 0.5336 - val_loss: 1.1263 - val_accuracy: 0.6559 - lr: 0.0010\n",
      "Epoch 7/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 1.3009 - accuracy: 0.5502 - val_loss: 1.0762 - val_accuracy: 0.6709 - lr: 0.0010\n",
      "Epoch 8/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 1.2510 - accuracy: 0.5703 - val_loss: 1.0326 - val_accuracy: 0.6936 - lr: 0.0010\n",
      "Epoch 9/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 1.2122 - accuracy: 0.5835 - val_loss: 0.9909 - val_accuracy: 0.7036 - lr: 0.0010\n",
      "Epoch 10/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 1.1710 - accuracy: 0.5970 - val_loss: 0.9571 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 11/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 1.1338 - accuracy: 0.6117 - val_loss: 0.9161 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 12/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 1.1046 - accuracy: 0.6188 - val_loss: 0.8835 - val_accuracy: 0.7417 - lr: 0.0010\n",
      "Epoch 13/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 1.0728 - accuracy: 0.6307 - val_loss: 0.8514 - val_accuracy: 0.7593 - lr: 0.0010\n",
      "Epoch 14/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 1.0399 - accuracy: 0.6417 - val_loss: 0.8192 - val_accuracy: 0.7714 - lr: 0.0010\n",
      "Epoch 15/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 1.0127 - accuracy: 0.6544 - val_loss: 0.7874 - val_accuracy: 0.7803 - lr: 0.0010\n",
      "Epoch 16/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.9907 - accuracy: 0.6588 - val_loss: 0.7624 - val_accuracy: 0.7868 - lr: 0.0010\n",
      "Epoch 17/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.9551 - accuracy: 0.6736 - val_loss: 0.7332 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 18/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.9288 - accuracy: 0.6827 - val_loss: 0.7051 - val_accuracy: 0.8023 - lr: 0.0010\n",
      "Epoch 19/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.9016 - accuracy: 0.6892 - val_loss: 0.6794 - val_accuracy: 0.8032 - lr: 0.0010\n",
      "Epoch 20/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.8821 - accuracy: 0.6964 - val_loss: 0.6528 - val_accuracy: 0.8113 - lr: 0.0010\n",
      "Epoch 21/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.8574 - accuracy: 0.7044 - val_loss: 0.6310 - val_accuracy: 0.8155 - lr: 0.0010\n",
      "Epoch 22/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.8320 - accuracy: 0.7133 - val_loss: 0.6095 - val_accuracy: 0.8225 - lr: 0.0010\n",
      "Epoch 23/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.8112 - accuracy: 0.7219 - val_loss: 0.5854 - val_accuracy: 0.8295 - lr: 0.0010\n",
      "Epoch 24/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.7939 - accuracy: 0.7244 - val_loss: 0.5655 - val_accuracy: 0.8343 - lr: 0.0010\n",
      "Epoch 25/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.7735 - accuracy: 0.7345 - val_loss: 0.5460 - val_accuracy: 0.8382 - lr: 0.0010\n",
      "Epoch 26/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.7515 - accuracy: 0.7401 - val_loss: 0.5288 - val_accuracy: 0.8422 - lr: 0.0010\n",
      "Epoch 27/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.7355 - accuracy: 0.7462 - val_loss: 0.5128 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 28/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.7219 - accuracy: 0.7501 - val_loss: 0.4967 - val_accuracy: 0.8481 - lr: 0.0010\n",
      "Epoch 29/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.6970 - accuracy: 0.7556 - val_loss: 0.4804 - val_accuracy: 0.8515 - lr: 0.0010\n",
      "Epoch 30/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.6857 - accuracy: 0.7587 - val_loss: 0.4672 - val_accuracy: 0.8567 - lr: 0.0010\n",
      "Epoch 31/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.6668 - accuracy: 0.7681 - val_loss: 0.4503 - val_accuracy: 0.8600 - lr: 0.0010\n",
      "Epoch 32/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.6489 - accuracy: 0.7724 - val_loss: 0.4403 - val_accuracy: 0.8590 - lr: 0.0010\n",
      "Epoch 33/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.6354 - accuracy: 0.7780 - val_loss: 0.4233 - val_accuracy: 0.8651 - lr: 0.0010\n",
      "Epoch 34/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.6241 - accuracy: 0.7801 - val_loss: 0.4141 - val_accuracy: 0.8673 - lr: 0.0010\n",
      "Epoch 35/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.6120 - accuracy: 0.7853 - val_loss: 0.4045 - val_accuracy: 0.8688 - lr: 0.0010\n",
      "Epoch 36/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.5958 - accuracy: 0.7888 - val_loss: 0.3929 - val_accuracy: 0.8707 - lr: 0.0010\n",
      "Epoch 37/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.5844 - accuracy: 0.7946 - val_loss: 0.3815 - val_accuracy: 0.8746 - lr: 0.0010\n",
      "Epoch 38/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.5727 - accuracy: 0.7967 - val_loss: 0.3711 - val_accuracy: 0.8745 - lr: 0.0010\n",
      "Epoch 39/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.5614 - accuracy: 0.8001 - val_loss: 0.3633 - val_accuracy: 0.8766 - lr: 0.0010\n",
      "Epoch 40/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.5522 - accuracy: 0.8031 - val_loss: 0.3544 - val_accuracy: 0.8797 - lr: 0.0010\n",
      "Epoch 41/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.5407 - accuracy: 0.8094 - val_loss: 0.3487 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 42/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.5302 - accuracy: 0.8113 - val_loss: 0.3398 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 43/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.5195 - accuracy: 0.8136 - val_loss: 0.3317 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 44/5000\n",
      "2690/2690 [==============================] - 25s 9ms/step - loss: 0.5128 - accuracy: 0.8155 - val_loss: 0.3258 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Epoch 45/5000\n",
      "1632/2690 [=================>............] - ETA: 9s - loss: 0.5111 - accuracy: 0.8178"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2938930/1360660779.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# fit the algorithm on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# calculate the evaluation metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Moji/TSC_Repo/dl4tsc/classifiers/mlp.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, x_val, y_val, y_true)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \t\thist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=nb_epochs,\n\u001b[0m\u001b[1;32m     73\u001b[0m \t\t\tverbose=self.verbose, validation_data=(x_val,y_val), callbacks=self.callbacks)\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# change this directory for your machine\n",
    "root_dir = './'\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# perform cross-validation for each dataset and algorithm combination\n",
    "for dataset in datasets:\n",
    "    Dataset_name = dataset + \"_Dataset\"\n",
    "    Dataset = np.load(datasets_path + \"/\" + Dataset_name + \".npy\")\n",
    "    \n",
    "\n",
    "    Labels_name = dataset + \"_Labels\"\n",
    "    Labels = np.load(datasets_path + \"/\"  + Labels_name + \".npy\")\n",
    "    \n",
    "\n",
    "\n",
    "    # Create a folder for results\n",
    "    results_path = root_dir + \"Results/\" + Dataset_name\n",
    "    if os.path.exists(results_path):\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            os.makedirs(results_path)\n",
    "        except:\n",
    "            # in case another machine created the path meanwhile !:(\n",
    "            pass\n",
    "\n",
    "        \n",
    "    t_total = time.time() ##Start timing\n",
    "    \n",
    "\n",
    "\n",
    "    print(f\"\\n The dataset shape is:{Dataset.shape}\")\n",
    "    print(f\"\\n The number of data samples (N) is:{Dataset.shape[0]}\")\n",
    "    print(f\"\\n The number of TS length (T) is:{Dataset.shape[1]}\")\n",
    "    print(f\"\\n The number of TS dimention (M) is:{Dataset.shape[2]}\")\n",
    "\n",
    "    nb_classes = len(np.unique(Labels, axis=0))\n",
    "    \n",
    "    # transform the labels from integers to one hot vectors\n",
    "    enc = sklearn.preprocessing.OneHotEncoder(categories='auto')\n",
    "    Labels = enc.fit_transform(Labels.reshape(-1, 1)).toarray()\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    report_list = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(Dataset)):\n",
    "        # split the data into training and testing sets\n",
    "        X_train, X_test = Dataset[train_idx], Dataset[test_idx]\n",
    "        y_train, y_test = Labels[train_idx], Labels[test_idx]\n",
    "        \n",
    "        # save orignal y because later we will use binary\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "        \n",
    "        input_shape = X_train.shape[1:]\n",
    "        \n",
    "        ## Create Classification module\n",
    "        from dl4tsc.classifiers import mlp\n",
    "        classifier = mlp.Classifier_MLP(output_directory=results_path, input_shape=input_shape,\n",
    "                                        nb_classes=nb_classes, verbose=True)\n",
    "        \n",
    "        # fit the algorithm on the training data\n",
    "        classifier.fit(X_train, y_train, X_test, y_test, y_true)\n",
    "            \n",
    "        # calculate the evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(accuracy)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(f1)\n",
    "\n",
    "        confusion = confusion_matrix(y_test, y_pred)\n",
    "        print(confusion)\n",
    "\n",
    "        accuracy_scores.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        confusion_matrices.append(confusion)\n",
    "\n",
    "        report = classification_report(y_test, y_pred, zero_division=1)\n",
    "        report_list.append(report)\n",
    "        print(report)\n",
    "        \n",
    "        print(f\" fold {fold+1} is Finished!\")\n",
    "        \n",
    "        # save the output to a text file\n",
    "        with open(f'{results_path}/dataset_{dataset_name}_LR_fold_{fold+1}.txt', 'w') as f:\n",
    "            f.write(f'Accuracy: {accuracy}\\n')\n",
    "            f.write(f'F1 Score: {f1}\\n')\n",
    "            f.write(f'Confusion Matrix:\\n{confusion}\\n\\n')\n",
    "            f.write(f'Classification report:\\n{report}\\n\\n')\n",
    "        \n",
    "    with open(f'{results_path}/dataset_{dataset_name}_LR.txt', 'w') as f:\n",
    "        f.write(\"Mean accuracy: {:.3f} (std={:.3f})\\n\".format(np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "        f.write(\"Mean F1 score: {:.3f} (std={:.3f})\\n\".format(np.mean(f1_scores), np.std(f1_scores)))\n",
    "        f.write(\"Mean confusion matrix:\\n{}\\n\".format(np.array2string(np.mean(confusion_matrices, axis=0))))\n",
    "\n",
    "    print(\" Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1670797391439,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "o0hfsmobe7o6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, duration, y_true_val=None, y_pred_val=None):\n",
    "    res = pd.DataFrame(data=np.zeros((1, 4), dtype=np.float), index=[0],\n",
    "                       columns=['precision', 'accuracy', 'recall', 'duration'])\n",
    "    res['precision'] = precision_score(y_true, y_pred, average='macro')\n",
    "    res['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    if not y_true_val is None:\n",
    "        # this is useful when transfer learning is used with cross validation\n",
    "        res['accuracy_val'] = accuracy_score(y_true_val, y_pred_val)\n",
    "\n",
    "    res['recall'] = recall_score(y_true, y_pred, average='macro')\n",
    "    res['duration'] = duration\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99
    },
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1670797392656,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "BIeCbOs6e7o6",
    "outputId": "973650ee-67f0-43ae-cf19-3b4bf69641fc"
   },
   "outputs": [],
   "source": [
    "classifier.predict(X_test, y_true,X_train,y_train,y_test,return_df_metrics = True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
