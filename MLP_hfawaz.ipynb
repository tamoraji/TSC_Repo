{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 19:19:45.942083: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-28 19:19:46.419921: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.12.0\n",
      "Keras Version: 2.12.0\n",
      "\n",
      "Python 3.9.16 (main, Mar  8 2023, 14:00:05) \n",
      "[GCC 11.2.0]\n",
      "Pandas 1.5.3\n",
      "Scikit-Learn 1.2.2\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 19:19:47.143731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-03-28 19:19:47.143923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-03-28 19:19:47.157330: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-03-28 19:19:47.157524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-03-28 19:19:47.157670: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-03-28 19:19:47.157807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670796275067,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "WI3EYR_be7ov"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670796275068,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "nYPPgDj2e7oy",
    "outputId": "c71b2a21-7bf6-46ac-c958-794ccd9e5531"
   },
   "outputs": [],
   "source": [
    "# define a list of datasets\n",
    "datasets = [\"PHM2022_Multivar\", \"PHM2022_Univar_PDIN\"]\n",
    "datasets_path = \"../datasets\"\n",
    "\n",
    "for dataset in datasets:\n",
    "    Dataset_name = dataset + \"_Dataset\"\n",
    "    Dataset = np.load(datasets_path + \"/\" + Dataset_name + \".npy\")\n",
    "    print(Dataset.shape)\n",
    "    \n",
    "\n",
    "    Labels_name = dataset + \"_Labels\"\n",
    "    Labels = np.load(datasets_path + \"/\"  + Labels_name + \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# change this directory for your machine\n",
    "root_dir = './'\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# perform cross-validation for each dataset and algorithm combination\n",
    "for dataset in datasets:\n",
    "    Dataset_name = dataset + \"_Dataset\"\n",
    "    Dataset = np.load(datasets_path + \"/\" + Dataset_name + \".npy\")\n",
    "    \n",
    "\n",
    "    Labels_name = dataset + \"_Labels\"\n",
    "    Labels = np.load(datasets_path + \"/\"  + Labels_name + \".npy\")\n",
    "    \n",
    "\n",
    "\n",
    "    # Create a folder for results\n",
    "    results_path = root_dir + \"Results/\" + Dataset_name\n",
    "    if os.path.exists(results_path):\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            os.makedirs(results_path)\n",
    "        except:\n",
    "            # in case another machine created the path meanwhile !:(\n",
    "            pass\n",
    "\n",
    "        \n",
    "    t_total = time.time() ##Start timing\n",
    "    \n",
    "\n",
    "\n",
    "    print(f\"\\n The dataset shape is:{Dataset.shape}\")\n",
    "    print(f\"\\n The number of data samples (N) is:{Dataset.shape[0]}\")\n",
    "    print(f\"\\n The number of TS length (T) is:{Dataset.shape[1]}\")\n",
    "    print(f\"\\n The number of TS dimention (M) is:{Dataset.shape[2]}\")\n",
    "\n",
    "    nb_classes = len(np.unique(Labels, axis=0))\n",
    "    \n",
    "    # transform the labels from integers to one hot vectors\n",
    "    enc = sklearn.preprocessing.OneHotEncoder(categories='auto')\n",
    "    Labels = enc.fit_transform(Labels.reshape(-1, 1)).toarray()\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    report_list = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(Dataset)):\n",
    "        # split the data into training and testing sets\n",
    "        X_train, X_test = Dataset[train_idx], Dataset[test_idx]\n",
    "        y_train, y_test = Labels[train_idx], Labels[test_idx]\n",
    "        \n",
    "        # save orignal y because later we will use binary\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "        \n",
    "        input_shape = X_train.shape[1:]\n",
    "        \n",
    "        ## Create Classification module\n",
    "        from dl4tsc.classifiers import mlp\n",
    "        classifier = mlp.Classifier_MLP(output_directory=results_path, input_shape=input_shape,\n",
    "                                        nb_classes=nb_classes, verbose=True)\n",
    "        \n",
    "        # fit the algorithm on the training data\n",
    "        classifier.fit(X_train, y_train, X_test, y_test, y_true)\n",
    "            \n",
    "        # calculate the evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(accuracy)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(f1)\n",
    "\n",
    "        confusion = confusion_matrix(y_test, y_pred)\n",
    "        print(confusion)\n",
    "\n",
    "        accuracy_scores.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        confusion_matrices.append(confusion)\n",
    "\n",
    "        report = classification_report(y_test, y_pred, zero_division=1)\n",
    "        report_list.append(report)\n",
    "        print(report)\n",
    "        \n",
    "        print(f\" fold {fold+1} is Finished!\")\n",
    "        \n",
    "        # save the output to a text file\n",
    "        with open(f'{results_path}/dataset_{dataset_name}_LR_fold_{fold+1}.txt', 'w') as f:\n",
    "            f.write(f'Accuracy: {accuracy}\\n')\n",
    "            f.write(f'F1 Score: {f1}\\n')\n",
    "            f.write(f'Confusion Matrix:\\n{confusion}\\n\\n')\n",
    "            f.write(f'Classification report:\\n{report}\\n\\n')\n",
    "        \n",
    "    with open(f'{results_path}/dataset_{dataset_name}_LR.txt', 'w') as f:\n",
    "        f.write(\"Mean accuracy: {:.3f} (std={:.3f})\\n\".format(np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "        f.write(\"Mean F1 score: {:.3f} (std={:.3f})\\n\".format(np.mean(f1_scores), np.std(f1_scores)))\n",
    "        f.write(\"Mean confusion matrix:\\n{}\\n\".format(np.array2string(np.mean(confusion_matrices, axis=0))))\n",
    "\n",
    "    print(\" Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1670797391439,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "o0hfsmobe7o6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, duration, y_true_val=None, y_pred_val=None):\n",
    "    res = pd.DataFrame(data=np.zeros((1, 4), dtype=np.float), index=[0],\n",
    "                       columns=['precision', 'accuracy', 'recall', 'duration'])\n",
    "    res['precision'] = precision_score(y_true, y_pred, average='macro')\n",
    "    res['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    if not y_true_val is None:\n",
    "        # this is useful when transfer learning is used with cross validation\n",
    "        res['accuracy_val'] = accuracy_score(y_true_val, y_pred_val)\n",
    "\n",
    "    res['recall'] = recall_score(y_true, y_pred, average='macro')\n",
    "    res['duration'] = duration\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99
    },
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1670797392656,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "BIeCbOs6e7o6",
    "outputId": "973650ee-67f0-43ae-cf19-3b4bf69641fc"
   },
   "outputs": [],
   "source": [
    "classifier.predict(X_test, y_true,X_train,y_train,y_test,return_df_metrics = True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
