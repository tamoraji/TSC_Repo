{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "from DANet.DA_Net import DA_Net\n",
    "from DANet.util import compute_F1_score, exponential_decay, save_result, plot_roc, random_seed\n",
    "from DANet.read_data import load_UEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "length = 1536 * 2\n",
    "parser = argparse.ArgumentParser(description='DA-Net for MTSC')\n",
    "\n",
    "#parser.add_argument('--model', type=str, default='DA-Net')\n",
    "parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "parser.add_argument('--length', type=int, default=8192, help='Embedding length')\n",
    "#parser.add_argument('--writer_path', type=str, default='runs/exp', help='TensorBoard path')\n",
    "parser.add_argument('--data_path', type=str, default=\"../datasets\")\n",
    "#parser.add_argument('--seed', type=int, default=1, help='random seed')\n",
    "parser.add_argument('--dropout', type=float, default=0.05, help='attention dropout rate')\n",
    "parser.add_argument('--batch_size', type=int, default=16)\n",
    "parser.add_argument('--n_epochs', type=int, default=2)\n",
    "parser.add_argument('--cache_path', type=str, default='./DANet/cache')\n",
    "parser.add_argument('--window', type=int, default=64)  # [32,48,64,80,96]\n",
    "parser.add_argument('--M_name', type=str, default='DA-Net')\n",
    "\n",
    "args = parser.parse_args(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataAndNet(archive_path, archive_name, wa, prob, mask=1):\n",
    "    train_loader, test_loader, num_class = load_UEA(X_train, X_test,y_train,y_test, args)\n",
    "\n",
    "    # get the length and channel of time series\n",
    "    time_stmp = train_loader.__iter__().next()[0].shape[2]\n",
    "    in_channel = train_loader.__iter__().next()[0].shape[1]\n",
    "    # num_class = DealDataset(train_path).num_class()\n",
    "\n",
    "    net = DA_Net(\n",
    "        t=time_stmp,\n",
    "        down_dim=length,\n",
    "        hidden_dim=(96, 192, 62),\n",
    "        layers=(2, 2, 6, 2),\n",
    "\n",
    "        heads=(3, 6, 12,24),\n",
    "        channels=in_channel,\n",
    "        num_classes=num_class,\n",
    "        head_dim=32,\n",
    "        window_size=args.window,\n",
    "        downscaling_factors=(4, 2, 2,2),  # 代表多长的时间作为一个特征\n",
    "\n",
    "        relative_pos_embedding=True,\n",
    "        wa=wa,\n",
    "        prob=prob,\n",
    "        mask=mask,\n",
    "    ).to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        net = torch.nn.DataParallel(net)\n",
    "    return train_loader, test_loader, net, num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    total_pred = torch.tensor([], dtype=torch.int64).to(device)\n",
    "    total_true = torch.tensor([], dtype=torch.int64).to(device)\n",
    "    score_list = []\n",
    "    label_list = []\n",
    "    total_test_acc = 0\n",
    "    # for batch_id, (x, y) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "    for batch_id, (x, y) in enumerate(test_loader):\n",
    "\n",
    "        x = Variable(x).float().to(device)\n",
    "        y = Variable(y).to(device)\n",
    "        net.eval()\n",
    "        start_time = time.time()\n",
    "        embedding, encoder, output, pred_y = net(x)\n",
    "        inference_time = time.time() - start_time\n",
    "\n",
    "        _, y_pred = torch.max(pred_y, -1)\n",
    "        total_test_acc += (y_pred.cpu() == y.cpu()).sum().item()\n",
    "\n",
    "        total_pred = torch.cat([total_pred, y_pred], dim=0)\n",
    "        total_true = torch.cat([total_true, y], dim=0)\n",
    "\n",
    "        test_loss = loss_func(pred_y, y.to(torch.long))\n",
    "\n",
    "        niter = epoch * test_loader.dataset.__len__() + batch_id\n",
    "        if niter % 10 == 0:\n",
    "            writer.add_scalar('Test Loss Curve {0}({1})'.format(M_name, length), test_loss.data.item(), niter)\n",
    "\n",
    "        score_list.extend(pred_y.detach().cpu().numpy())\n",
    "        label_list.extend(y.cpu().numpy())\n",
    "\n",
    "    #plot_roc( num_class, label_list, score_list, L=length)\n",
    "\n",
    "    f1_score, precision, recall = compute_F1_score(total_true, total_pred)\n",
    "\n",
    "    return total_test_acc, f1_score, precision, recall, inference_time, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer):\n",
    "    train_time = 0\n",
    "    max_accuracy = 0\n",
    "    plot_train_loss = []\n",
    "    plot_test_loss = []\n",
    "    plot_train_acc = []\n",
    "    plot_test_acc = []\n",
    "    for epoch in range(n_epochs):\n",
    "        ls = []\n",
    "        s_time = time.time()\n",
    "        total_train_acc = 0\n",
    "\n",
    "\n",
    "        # for batch_id,(x,y) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        for batch_id, (x, y) in enumerate(train_loader):\n",
    "            #torch ALEXNET\n",
    "            net.train()\n",
    "            optimizer = exponential_decay(optimizer, LEARNING_RATE, global_epoch, 1, 0.90)\n",
    "\n",
    "            x = Variable(x).float().to(device)\n",
    "            y = Variable(y).to(device)\n",
    "            # output 我们需要的 all_sample\n",
    "            embedding, encoder, output, pred_y = net(x)\n",
    "            # loss\n",
    "            loss = loss_func(pred_y, y.to(torch.long))\n",
    "\n",
    "            _, y_pred = torch.max(pred_y, -1)\n",
    "            acc_train = (y_pred.cpu() == y.cpu()).sum().item()\n",
    "            total_train_acc += acc_train\n",
    "            niter = epoch * train_loader.dataset.__len__() + batch_id\n",
    "\n",
    "            #if niter % 10 == 0:\n",
    "                #writer.add_scalar('Train Loss Curve {0}({1})'.format(M_name, length), loss.data.item(), niter)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, y_pred = torch.max(pred_y, -1)\n",
    "            ls.append(loss)\n",
    "\n",
    "        print('Epoch: {:04d}'.format(epoch + 1),\n",
    "              'loss_train: {:.8f}'.format(loss.item()),\n",
    "              'acc_train: {:.4f}'.format(total_train_acc / train_loader.dataset.__len__()),\n",
    "              'time: {:.4f}s'.format(time.time() - s_time))\n",
    "        plot_train_loss.append(loss.item())\n",
    "        plot_train_acc.append(total_train_acc / train_loader.dataset.__len__())\n",
    "        train_time += time.time() - s_time\n",
    "\n",
    "        # print(\"Total time elapsed: {:.4f}s\".format(train_time))\n",
    "        total_test_acc, f1_score, precision, recall, inference_time, test_loss = test(epoch)\n",
    "        plot_test_loss.append(test_loss.cpu().detach())\n",
    "        plot_test_acc.append(total_test_acc / test_loader.dataset.__len__())\n",
    "\n",
    "        # save model\n",
    "        if os.path.exists(f'saved_model/{M_name}') == False:\n",
    "            os.makedirs(f'saved_model/{M_name}')\n",
    "\n",
    "        if total_test_acc > max_accuracy:\n",
    "            print('save best model')\n",
    "            max_accuracy = total_test_acc\n",
    "            torch.save(net,\n",
    "                       f'saved_model/{M_name}/{archive} batch={args.batch_size} length={length} window={args.window}.pkl')\n",
    "\n",
    "        print('Epoch: {:04d}'.format(epoch + 1),\n",
    "              'loss_test: {:.8f}'.format(test_loss.item()),\n",
    "              'acc_test: {:.4f}'.format(total_test_acc / test_loader.dataset.__len__()),\n",
    "              'time: {:.4f}s'.format(time.time() - s_time))\n",
    "    #plt.plot()\n",
    "\n",
    "    if os.path.exists(f'result') == False:\n",
    "        os.makedirs(f'result')\n",
    "    save_result(file, ls[-1], total_test_acc / test_loader.dataset.__len__(), f1_score, precision, recall, train_time,\n",
    "                inference_time, args.window, length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670796275068,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "nYPPgDj2e7oy",
    "outputId": "c71b2a21-7bf6-46ac-c958-794ccd9e5531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53785, 749, 3)\n",
      "(53785, 749, 1)\n"
     ]
    }
   ],
   "source": [
    "# define a list of datasets\n",
    "datasets = [\"PHM2022_Multivar\", \"PHM2022_Univar_PDIN\"]\n",
    "datasets_path = \"../datasets\"\n",
    "\n",
    "for dataset in datasets:\n",
    "    Dataset_name = dataset + \"_Dataset\"\n",
    "    Dataset = np.load(datasets_path + \"/\" + Dataset_name + \".npy\")\n",
    "    print(Dataset.shape)\n",
    "    \n",
    "\n",
    "    Labels_name = dataset + \"_Labels\"\n",
    "    Labels = np.load(datasets_path + \"/\"  + Labels_name + \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The dataset shape is:(53785, 749, 3)\n",
      "\n",
      " The number of data samples (N) is:53785\n",
      "\n",
      " The number of TS length (T) is:749\n",
      "\n",
      " The number of TS dimention (M) is:3\n"
     ]
    }
   ],
   "source": [
    "# change this directory for your machine\n",
    "root_dir = './'\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# perform cross-validation for each dataset and algorithm combination\n",
    "for dataset in datasets:\n",
    "    Dataset_name = dataset + \"_Dataset\"\n",
    "    Dataset = np.load(datasets_path + \"/\" + Dataset_name + \".npy\")\n",
    "    \n",
    "\n",
    "    Labels_name = dataset + \"_Labels\"\n",
    "    Labels = np.load(datasets_path + \"/\"  + Labels_name + \".npy\")\n",
    "    \n",
    "\n",
    "\n",
    "    # Create a folder for results\n",
    "    results_path = root_dir + \"Results/\" + Dataset_name\n",
    "    if os.path.exists(results_path):\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            os.makedirs(results_path)\n",
    "        except:\n",
    "            # in case another machine created the path meanwhile !:(\n",
    "            pass\n",
    "\n",
    "        \n",
    "    t_total = time.time() ##Start timing\n",
    "    \n",
    "\n",
    "\n",
    "    print(f\"\\n The dataset shape is:{Dataset.shape}\")\n",
    "    print(f\"\\n The number of data samples (N) is:{Dataset.shape[0]}\")\n",
    "    print(f\"\\n The number of TS length (T) is:{Dataset.shape[1]}\")\n",
    "    print(f\"\\n The number of TS dimention (M) is:{Dataset.shape[2]}\")\n",
    "\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    report_list = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(Dataset)):\n",
    "        # split the data into training and testing sets\n",
    "        X_train, X_test = Dataset[train_idx], Dataset[test_idx]\n",
    "        y_train, y_test = Labels[train_idx], Labels[test_idx]\n",
    "        \n",
    "        wa=1\n",
    "        prob=1\n",
    "\n",
    "        train_loader, test_loader, net, num_class = GetDataAndNet(0, Dataset_name, wa, prob)\n",
    "\n",
    "        LEARNING_RATE = 0.001\n",
    "        optimizer = torch.optim.Adam(\n",
    "            net.parameters(),\n",
    "            lr=10,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-08)\n",
    "        global_epoch = 0\n",
    "        global_step = 0\n",
    "        best_tst_accuracy = 0.0\n",
    "        COMPUTE_TRN_METRICS = True\n",
    "        n_epochs = args.n_epochs\n",
    "\n",
    "        loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        ## Create Classification module\n",
    "        train(optimizer)\n",
    "        \n",
    "\n",
    "            \n",
    "        # calculate the evaluation metrics\n",
    "        accuracy = total_test_acc\n",
    "        print(accuracy)\n",
    "\n",
    "        f1 = f1_score\n",
    "        print(f1)\n",
    "\n",
    "        confusion = confusion_matrix(y_test, y_pred)\n",
    "        print(confusion)\n",
    "\n",
    "        accuracy_scores.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        confusion_matrices.append(confusion)\n",
    "\n",
    "        report = classification_report(y_test, y_pred, zero_division=1)\n",
    "        report_list.append(report)\n",
    "        print(report)\n",
    "        \n",
    "        print(f\" fold {fold+1} is Finished!\")\n",
    "        \n",
    "        # save the output to a text file\n",
    "        with open(f'{results_path}/dataset_{dataset_name}_DANet_fold_{fold+1}.txt', 'w') as f:\n",
    "            f.write(f'Accuracy: {accuracy}\\n')\n",
    "            f.write(f'F1 Score: {f1}\\n')\n",
    "            f.write(f'Confusion Matrix:\\n{confusion}\\n\\n')\n",
    "            f.write(f'Classification report:\\n{report}\\n\\n')\n",
    "        \n",
    "    with open(f'{results_path}/dataset_{dataset_name}_DANet.txt', 'w') as f:\n",
    "        f.write(\"Mean accuracy: {:.3f} (std={:.3f})\\n\".format(np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "        f.write(\"Mean F1 score: {:.3f} (std={:.3f})\\n\".format(np.mean(f1_scores), np.std(f1_scores)))\n",
    "        f.write(\"Mean confusion matrix:\\n{}\\n\".format(np.array2string(np.mean(confusion_matrices, axis=0))))\n",
    "        f.write(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "    print(\" Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1670797391439,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "o0hfsmobe7o6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, duration, y_true_val=None, y_pred_val=None):\n",
    "    res = pd.DataFrame(data=np.zeros((1, 4), dtype=np.float), index=[0],\n",
    "                       columns=['precision', 'accuracy', 'recall', 'duration'])\n",
    "    res['precision'] = precision_score(y_true, y_pred, average='macro')\n",
    "    res['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    if not y_true_val is None:\n",
    "        # this is useful when transfer learning is used with cross validation\n",
    "        res['accuracy_val'] = accuracy_score(y_true_val, y_pred_val)\n",
    "\n",
    "    res['recall'] = recall_score(y_true, y_pred, average='macro')\n",
    "    res['duration'] = duration\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_metrics \u001b[38;5;241m=\u001b[39m calculate_metrics(\u001b[43my_true\u001b[49m, y_pred, \u001b[38;5;241m0.0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "df_metrics = calculate_metrics(y_true, y_pred, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99
    },
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1670797392656,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "BIeCbOs6e7o6",
    "outputId": "973650ee-67f0-43ae-cf19-3b4bf69641fc"
   },
   "outputs": [],
   "source": [
    "classifier.predict(X_test, y_true,X_train,y_train,y_test,return_df_metrics = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File('./Results/PHM2022_Multivar_Datasetbest_model.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_weights', 'optimizer_weights']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
