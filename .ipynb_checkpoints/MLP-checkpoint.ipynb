{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pip install tensorflow==2.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge cudatoolkit=11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.11.0\n",
      "Keras Version: 2.11.0\n",
      "\n",
      "Python 3.9.16 (main, Mar  8 2023, 14:00:05) \n",
      "[GCC 11.2.0]\n",
      "Pandas 1.5.3\n",
      "Scikit-Learn 1.2.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670796275067,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "WI3EYR_be7ov"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670796275068,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "nYPPgDj2e7oy",
    "outputId": "c71b2a21-7bf6-46ac-c958-794ccd9e5531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53785, 749, 3)\n",
      "(53785, 749, 1)\n"
     ]
    }
   ],
   "source": [
    "# define a list of datasets\n",
    "datasets = [\n",
    "\"BEARING_Univar\",\n",
    "\"PHM2022_Multivar\",\n",
    "\"PHM2022_Univar_PIN\",\n",
    "\"PHM2022_Univar_PO\",\n",
    "\"PHM2022_Univar_PDIN\",\n",
    "\"ETCHING_Multivar\",\n",
    "\"MFPT_48KHZ_Univar\",\n",
    "\"MFPT_96KHZ_Univar\",\n",
    "\"PADERBORN_6KHZ_Univar\",\n",
    "\"PADERBORN_4KHZ_Univar\",\n",
    "\"PADERBORN_64KHZ_Multivar\",\n",
    "\"PADERBORN_4KHZ_Multivar\",\n",
    "\"Hydraulic_systems_10HZ_Multivar\",\n",
    "\"Hydraulic_systems_100HZ_Multivar\",\n",
    "\"Gas_sensors_home_activity\",\n",
    "\"Control_charts\",\n",
    "\"CWRU_12k_DE_univar\",\n",
    "\"CWRU_12k_DE_multivar\",\n",
    "\"CWRU_12k_FE_univar\",\n",
    "\"CWRU_12k_FE_multivar\",\n",
    "\"CWRU_48k_DE_univar\",\n",
    "\"CWRU_48k_DE_multivar\"\n",
    "]\n",
    "#datasets = [\"PHM2022_Multivar\", \"PHM2022_Univar_PDIN\"]\n",
    "datasets_path = \"../datasets\"\n",
    "\n",
    "for dataset in datasets:\n",
    "    Dataset_name = dataset + \"_Dataset\"\n",
    "    Dataset = np.load(datasets_path + \"/\" + Dataset_name + \".npy\")\n",
    "    print(Dataset.shape)\n",
    "    \n",
    "\n",
    "    Labels_name = dataset + \"_Labels\"\n",
    "    Labels = np.load(datasets_path + \"/\"  + Labels_name + \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The dataset shape is:(53785, 749, 3)\n",
      "\n",
      " The number of data samples (N) is:53785\n",
      "\n",
      " The number of TS length (T) is:749\n",
      "\n",
      " The number of TS dimention (M) is:3\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 749, 3)]          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2247)              0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 2247)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 500)               1124000   \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 12)                6012      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,631,012\n",
      "Trainable params: 1,631,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5000\n",
      "2690/2690 [==============================] - 9s 3ms/step - loss: 2.0897 - accuracy: 0.3487 - val_loss: 1.6499 - val_accuracy: 0.4368 - lr: 0.0010\n",
      "Epoch 2/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 1.7460 - accuracy: 0.4247 - val_loss: 1.4755 - val_accuracy: 0.4852 - lr: 0.0010\n",
      "Epoch 3/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 1.5888 - accuracy: 0.4590 - val_loss: 1.3702 - val_accuracy: 0.5265 - lr: 0.0010\n",
      "Epoch 4/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 1.4930 - accuracy: 0.4852 - val_loss: 1.2929 - val_accuracy: 0.5662 - lr: 0.0010\n",
      "Epoch 5/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 1.4187 - accuracy: 0.5063 - val_loss: 1.2253 - val_accuracy: 0.6033 - lr: 0.0010\n",
      "Epoch 6/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 1.3596 - accuracy: 0.5267 - val_loss: 1.1680 - val_accuracy: 0.6257 - lr: 0.0010\n",
      "Epoch 7/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 1.3076 - accuracy: 0.5485 - val_loss: 1.1210 - val_accuracy: 0.6399 - lr: 0.0010\n",
      "Epoch 8/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 1.2627 - accuracy: 0.5639 - val_loss: 1.0727 - val_accuracy: 0.6573 - lr: 0.0010\n",
      "Epoch 9/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 1.2177 - accuracy: 0.5774 - val_loss: 1.0306 - val_accuracy: 0.6736 - lr: 0.0010\n",
      "Epoch 10/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 1.1767 - accuracy: 0.5946 - val_loss: 0.9883 - val_accuracy: 0.6899 - lr: 0.0010\n",
      "Epoch 11/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 1.1376 - accuracy: 0.6092 - val_loss: 0.9498 - val_accuracy: 0.7073 - lr: 0.0010\n",
      "Epoch 12/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 1.1018 - accuracy: 0.6188 - val_loss: 0.9147 - val_accuracy: 0.7227 - lr: 0.0010\n",
      "Epoch 13/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 1.0735 - accuracy: 0.6305 - val_loss: 0.8777 - val_accuracy: 0.7402 - lr: 0.0010\n",
      "Epoch 14/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 1.0369 - accuracy: 0.6422 - val_loss: 0.8455 - val_accuracy: 0.7496 - lr: 0.0010\n",
      "Epoch 15/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 1.0048 - accuracy: 0.6549 - val_loss: 0.8115 - val_accuracy: 0.7621 - lr: 0.0010\n",
      "Epoch 16/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.9780 - accuracy: 0.6630 - val_loss: 0.7836 - val_accuracy: 0.7673 - lr: 0.0010\n",
      "Epoch 17/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.9483 - accuracy: 0.6728 - val_loss: 0.7515 - val_accuracy: 0.7775 - lr: 0.0010\n",
      "Epoch 18/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.9220 - accuracy: 0.6787 - val_loss: 0.7204 - val_accuracy: 0.7906 - lr: 0.0010\n",
      "Epoch 19/5000\n",
      "2690/2690 [==============================] - 6s 2ms/step - loss: 0.8934 - accuracy: 0.6903 - val_loss: 0.6929 - val_accuracy: 0.7981 - lr: 0.0010\n",
      "Epoch 20/5000\n",
      "2690/2690 [==============================] - 5s 2ms/step - loss: 0.8677 - accuracy: 0.6991 - val_loss: 0.6709 - val_accuracy: 0.8018 - lr: 0.0010\n",
      "Epoch 21/5000\n",
      "2690/2690 [==============================] - 5s 2ms/step - loss: 0.8444 - accuracy: 0.7064 - val_loss: 0.6454 - val_accuracy: 0.8111 - lr: 0.0010\n",
      "Epoch 22/5000\n",
      "2690/2690 [==============================] - 5s 2ms/step - loss: 0.8244 - accuracy: 0.7104 - val_loss: 0.6214 - val_accuracy: 0.8210 - lr: 0.0010\n",
      "Epoch 23/5000\n",
      "2690/2690 [==============================] - 5s 2ms/step - loss: 0.7979 - accuracy: 0.7210 - val_loss: 0.6003 - val_accuracy: 0.8269 - lr: 0.0010\n",
      "Epoch 24/5000\n",
      "2690/2690 [==============================] - 5s 2ms/step - loss: 0.7776 - accuracy: 0.7259 - val_loss: 0.5828 - val_accuracy: 0.8264 - lr: 0.0010\n",
      "Epoch 25/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.7536 - accuracy: 0.7348 - val_loss: 0.5609 - val_accuracy: 0.8343 - lr: 0.0010\n",
      "Epoch 26/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.7382 - accuracy: 0.7395 - val_loss: 0.5417 - val_accuracy: 0.8379 - lr: 0.0010\n",
      "Epoch 27/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.7212 - accuracy: 0.7488 - val_loss: 0.5228 - val_accuracy: 0.8449 - lr: 0.0010\n",
      "Epoch 28/5000\n",
      "2690/2690 [==============================] - 7s 2ms/step - loss: 0.7013 - accuracy: 0.7526 - val_loss: 0.5094 - val_accuracy: 0.8464 - lr: 0.0010\n",
      "Epoch 29/5000\n",
      "2690/2690 [==============================] - 7s 2ms/step - loss: 0.6866 - accuracy: 0.7574 - val_loss: 0.4905 - val_accuracy: 0.8537 - lr: 0.0010\n",
      "Epoch 30/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.6668 - accuracy: 0.7624 - val_loss: 0.4782 - val_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 31/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.6510 - accuracy: 0.7683 - val_loss: 0.4605 - val_accuracy: 0.8619 - lr: 0.0010\n",
      "Epoch 32/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.6321 - accuracy: 0.7757 - val_loss: 0.4440 - val_accuracy: 0.8689 - lr: 0.0010\n",
      "Epoch 33/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.6218 - accuracy: 0.7782 - val_loss: 0.4338 - val_accuracy: 0.8695 - lr: 0.0010\n",
      "Epoch 34/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.6099 - accuracy: 0.7830 - val_loss: 0.4232 - val_accuracy: 0.8722 - lr: 0.0010\n",
      "Epoch 35/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.5979 - accuracy: 0.7874 - val_loss: 0.4156 - val_accuracy: 0.8711 - lr: 0.0010\n",
      "Epoch 36/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.5812 - accuracy: 0.7923 - val_loss: 0.4047 - val_accuracy: 0.8741 - lr: 0.0010\n",
      "Epoch 37/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.5694 - accuracy: 0.7969 - val_loss: 0.3918 - val_accuracy: 0.8768 - lr: 0.0010\n",
      "Epoch 38/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.5564 - accuracy: 0.7998 - val_loss: 0.3838 - val_accuracy: 0.8785 - lr: 0.0010\n",
      "Epoch 39/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.5495 - accuracy: 0.8034 - val_loss: 0.3716 - val_accuracy: 0.8831 - lr: 0.0010\n",
      "Epoch 40/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.5372 - accuracy: 0.8074 - val_loss: 0.3650 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Epoch 41/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.5270 - accuracy: 0.8093 - val_loss: 0.3562 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 42/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.5196 - accuracy: 0.8143 - val_loss: 0.3499 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 43/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.5098 - accuracy: 0.8147 - val_loss: 0.3436 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Epoch 44/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.4989 - accuracy: 0.8191 - val_loss: 0.3370 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Epoch 45/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.4894 - accuracy: 0.8248 - val_loss: 0.3281 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Epoch 46/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.4836 - accuracy: 0.8238 - val_loss: 0.3203 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Epoch 47/5000\n",
      "2690/2690 [==============================] - 6s 2ms/step - loss: 0.4776 - accuracy: 0.8263 - val_loss: 0.3162 - val_accuracy: 0.8955 - lr: 0.0010\n",
      "Epoch 48/5000\n",
      "2690/2690 [==============================] - 6s 2ms/step - loss: 0.4699 - accuracy: 0.8290 - val_loss: 0.3125 - val_accuracy: 0.8966 - lr: 0.0010\n",
      "Epoch 49/5000\n",
      "2690/2690 [==============================] - 6s 2ms/step - loss: 0.4612 - accuracy: 0.8315 - val_loss: 0.3064 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 50/5000\n",
      "2690/2690 [==============================] - 6s 2ms/step - loss: 0.4544 - accuracy: 0.8358 - val_loss: 0.2978 - val_accuracy: 0.9030 - lr: 0.0010\n",
      "Epoch 51/5000\n",
      "2690/2690 [==============================] - 7s 2ms/step - loss: 0.4468 - accuracy: 0.8370 - val_loss: 0.2940 - val_accuracy: 0.9031 - lr: 0.0010\n",
      "Epoch 52/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.4369 - accuracy: 0.8408 - val_loss: 0.2893 - val_accuracy: 0.9040 - lr: 0.0010\n",
      "Epoch 53/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.4311 - accuracy: 0.8425 - val_loss: 0.2834 - val_accuracy: 0.9051 - lr: 0.0010\n",
      "Epoch 54/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.4293 - accuracy: 0.8426 - val_loss: 0.2806 - val_accuracy: 0.9065 - lr: 0.0010\n",
      "Epoch 55/5000\n",
      "2690/2690 [==============================] - 6s 2ms/step - loss: 0.4203 - accuracy: 0.8454 - val_loss: 0.2746 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 56/5000\n",
      "2690/2690 [==============================] - 7s 2ms/step - loss: 0.4124 - accuracy: 0.8486 - val_loss: 0.2718 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 57/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.4082 - accuracy: 0.8491 - val_loss: 0.2679 - val_accuracy: 0.9099 - lr: 0.0010\n",
      "Epoch 58/5000\n",
      "2690/2690 [==============================] - 7s 2ms/step - loss: 0.4035 - accuracy: 0.8516 - val_loss: 0.2626 - val_accuracy: 0.9137 - lr: 0.0010\n",
      "Epoch 59/5000\n",
      "2690/2690 [==============================] - 6s 2ms/step - loss: 0.3971 - accuracy: 0.8554 - val_loss: 0.2587 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Epoch 60/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.3923 - accuracy: 0.8568 - val_loss: 0.2546 - val_accuracy: 0.9145 - lr: 0.0010\n",
      "Epoch 61/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3879 - accuracy: 0.8581 - val_loss: 0.2515 - val_accuracy: 0.9145 - lr: 0.0010\n",
      "Epoch 62/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3817 - accuracy: 0.8583 - val_loss: 0.2477 - val_accuracy: 0.9169 - lr: 0.0010\n",
      "Epoch 63/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3805 - accuracy: 0.8583 - val_loss: 0.2473 - val_accuracy: 0.9153 - lr: 0.0010\n",
      "Epoch 64/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3746 - accuracy: 0.8616 - val_loss: 0.2416 - val_accuracy: 0.9161 - lr: 0.0010\n",
      "Epoch 65/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3701 - accuracy: 0.8639 - val_loss: 0.2378 - val_accuracy: 0.9200 - lr: 0.0010\n",
      "Epoch 66/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3661 - accuracy: 0.8646 - val_loss: 0.2358 - val_accuracy: 0.9198 - lr: 0.0010\n",
      "Epoch 67/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3638 - accuracy: 0.8649 - val_loss: 0.2328 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 68/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3567 - accuracy: 0.8683 - val_loss: 0.2313 - val_accuracy: 0.9203 - lr: 0.0010\n",
      "Epoch 69/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.3539 - accuracy: 0.8685 - val_loss: 0.2278 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Epoch 70/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.3484 - accuracy: 0.8699 - val_loss: 0.2264 - val_accuracy: 0.9204 - lr: 0.0010\n",
      "Epoch 71/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.3422 - accuracy: 0.8745 - val_loss: 0.2227 - val_accuracy: 0.9245 - lr: 0.0010\n",
      "Epoch 72/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.3411 - accuracy: 0.8718 - val_loss: 0.2182 - val_accuracy: 0.9275 - lr: 0.0010\n",
      "Epoch 73/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.3366 - accuracy: 0.8759 - val_loss: 0.2187 - val_accuracy: 0.9240 - lr: 0.0010\n",
      "Epoch 74/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3377 - accuracy: 0.8749 - val_loss: 0.2139 - val_accuracy: 0.9267 - lr: 0.0010\n",
      "Epoch 75/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3322 - accuracy: 0.8767 - val_loss: 0.2121 - val_accuracy: 0.9261 - lr: 0.0010\n",
      "Epoch 76/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3295 - accuracy: 0.8778 - val_loss: 0.2130 - val_accuracy: 0.9247 - lr: 0.0010\n",
      "Epoch 77/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3257 - accuracy: 0.8780 - val_loss: 0.2073 - val_accuracy: 0.9290 - lr: 0.0010\n",
      "Epoch 78/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3226 - accuracy: 0.8793 - val_loss: 0.2062 - val_accuracy: 0.9293 - lr: 0.0010\n",
      "Epoch 79/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3172 - accuracy: 0.8806 - val_loss: 0.2028 - val_accuracy: 0.9310 - lr: 0.0010\n",
      "Epoch 80/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3153 - accuracy: 0.8826 - val_loss: 0.2008 - val_accuracy: 0.9320 - lr: 0.0010\n",
      "Epoch 81/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.3114 - accuracy: 0.8846 - val_loss: 0.1984 - val_accuracy: 0.9333 - lr: 0.0010\n",
      "Epoch 82/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.3100 - accuracy: 0.8838 - val_loss: 0.1974 - val_accuracy: 0.9319 - lr: 0.0010\n",
      "Epoch 83/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.3082 - accuracy: 0.8849 - val_loss: 0.1950 - val_accuracy: 0.9342 - lr: 0.0010\n",
      "Epoch 84/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.3061 - accuracy: 0.8856 - val_loss: 0.1926 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 85/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.2996 - accuracy: 0.8888 - val_loss: 0.1938 - val_accuracy: 0.9324 - lr: 0.0010\n",
      "Epoch 86/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.2983 - accuracy: 0.8884 - val_loss: 0.1900 - val_accuracy: 0.9347 - lr: 0.0010\n",
      "Epoch 87/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.2924 - accuracy: 0.8921 - val_loss: 0.1882 - val_accuracy: 0.9362 - lr: 0.0010\n",
      "Epoch 88/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.2920 - accuracy: 0.8921 - val_loss: 0.1857 - val_accuracy: 0.9363 - lr: 0.0010\n",
      "Epoch 89/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.2913 - accuracy: 0.8909 - val_loss: 0.1845 - val_accuracy: 0.9378 - lr: 0.0010\n",
      "Epoch 90/5000\n",
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.2883 - accuracy: 0.8927 - val_loss: 0.1845 - val_accuracy: 0.9374 - lr: 0.0010\n",
      "Epoch 91/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2690/2690 [==============================] - 7s 3ms/step - loss: 0.2858 - accuracy: 0.8930 - val_loss: 0.1808 - val_accuracy: 0.9385 - lr: 0.0010\n",
      "Epoch 92/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.2800 - accuracy: 0.8953 - val_loss: 0.1810 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "Epoch 93/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.2800 - accuracy: 0.8949 - val_loss: 0.1787 - val_accuracy: 0.9394 - lr: 0.0010\n",
      "Epoch 94/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.2755 - accuracy: 0.8988 - val_loss: 0.1773 - val_accuracy: 0.9396 - lr: 0.0010\n",
      "Epoch 95/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.2766 - accuracy: 0.8966 - val_loss: 0.1754 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 96/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.2701 - accuracy: 0.9009 - val_loss: 0.1769 - val_accuracy: 0.9377 - lr: 0.0010\n",
      "Epoch 97/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.2723 - accuracy: 0.8993 - val_loss: 0.1727 - val_accuracy: 0.9412 - lr: 0.0010\n",
      "Epoch 98/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.2691 - accuracy: 0.8988 - val_loss: 0.1714 - val_accuracy: 0.9419 - lr: 0.0010\n",
      "Epoch 99/5000\n",
      "2690/2690 [==============================] - 8s 3ms/step - loss: 0.2682 - accuracy: 0.9000 - val_loss: 0.1685 - val_accuracy: 0.9439 - lr: 0.0010\n",
      "Epoch 100/5000\n",
      "2610/2690 [============================>.] - ETA: 0s - loss: 0.2634 - accuracy: 0.9025"
     ]
    }
   ],
   "source": [
    "# change this directory for your machine\n",
    "root_dir = './'\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# perform cross-validation for each dataset and algorithm combination\n",
    "for dataset in datasets:\n",
    "    Dataset_name = dataset + \"_Dataset\"\n",
    "    Dataset = np.load(datasets_path + \"/\" + Dataset_name + \".npy\")\n",
    "    start = time.time() ##Start timing\n",
    "    print(f\"Starting to work on {Dataset_name} at {start}\")\n",
    "\n",
    "    Labels_name = dataset + \"_Labels\"\n",
    "    Labels = np.load(datasets_path + \"/\"  + Labels_name + \".npy\")\n",
    "    \n",
    "\n",
    "\n",
    "    # Create a folder for results\n",
    "    results_path = root_dir + \"Results/\" + Dataset_name\n",
    "    if os.path.exists(results_path):\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            os.makedirs(results_path)\n",
    "        except:\n",
    "            # in case another machine created the path meanwhile !:(\n",
    "            pass\n",
    "\n",
    "        \n",
    "    t_total = time.time() ##Start timing\n",
    "    \n",
    "\n",
    "\n",
    "    print(f\"\\n The dataset shape is:{Dataset.shape}\")\n",
    "    print(f\"\\n The number of data samples (N) is:{Dataset.shape[0]}\")\n",
    "    print(f\"\\n The number of TS length (T) is:{Dataset.shape[1]}\")\n",
    "    print(f\"\\n The number of TS dimention (M) is:{Dataset.shape[2]}\")\n",
    "\n",
    "    nb_classes = len(np.unique(Labels, axis=0))\n",
    "    \n",
    "    # transform the labels from integers to one hot vectors\n",
    "    enc = sklearn.preprocessing.OneHotEncoder(categories='auto')\n",
    "    Labels = enc.fit_transform(Labels.reshape(-1, 1)).toarray()\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    report_list = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(Dataset)):\n",
    "        # split the data into training and testing sets\n",
    "        X_train, X_test = Dataset[train_idx], Dataset[test_idx]\n",
    "        y_train, y_test = Labels[train_idx], Labels[test_idx]\n",
    "        \n",
    "        # save orignal y because later we will use binary\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "        \n",
    "        input_shape = X_train.shape[1:]\n",
    "        \n",
    "        ## Create Classification module\n",
    "        from dl4tsc.classifiers import mlp\n",
    "        classifier = mlp.Classifier_MLP(output_directory=results_path, input_shape=input_shape,\n",
    "                                        nb_classes=nb_classes, verbose=True)\n",
    "        \n",
    "        # fit the algorithm on the training data\n",
    "        accuracy, f1, confusion, report = classifier.fit(X_train, y_train, X_test, y_test, y_true)\n",
    "            \n",
    "        # calculate the evaluation metrics\n",
    "        accuracy_scores.append(accuracy)\n",
    "        print(accuracy)\n",
    "\n",
    "        f1_scores.append(f1)\n",
    "        print(f1)\n",
    "\n",
    "        confusion_matrices.append(confusion)\n",
    "        print(confusion)\n",
    "\n",
    "        report_list.append(report)\n",
    "        print(report)\n",
    "        \n",
    "        print(f\" fold {fold+1} is Finished!\")\n",
    "        keras.backend.clear_session()\n",
    "        \n",
    "        # save the output to a text file\n",
    "        with open(f'{results_path}/dataset_{Dataset_name}_MLP_fold_{fold+1}.txt', 'w') as f:\n",
    "            f.write(f'Accuracy: {accuracy}\\n')\n",
    "            f.write(f'F1 Score: {f1}\\n')\n",
    "            f.write(f'Confusion Matrix:\\n{confusion}\\n\\n')\n",
    "            f.write(f'Classification report:\\n{report}\\n\\n')\n",
    "        \n",
    "    with open(f'{results_path}/dataset_{Dataset_name}_MLP.txt', 'w') as f:\n",
    "        f.write(\"Mean accuracy: {:.4f} (std={:.3f})\\n\".format(np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "        f.write(\"Mean F1 score: {:.4f} (std={:.3f})\\n\".format(np.mean(f1_scores), np.std(f1_scores)))\n",
    "        f.write(\"Mean confusion matrix:\\n{}\\n\".format(np.array2string(np.mean(confusion_matrices, axis=0))))\n",
    "        f.write(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "    print(\" Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "    print(f\"Working on {Dataset_name} finished successfully!\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1670797391439,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "o0hfsmobe7o6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, duration, y_true_val=None, y_pred_val=None):\n",
    "    res = pd.DataFrame(data=np.zeros((1, 4), dtype=np.float), index=[0],\n",
    "                       columns=['precision', 'accuracy', 'recall', 'duration'])\n",
    "    res['precision'] = precision_score(y_true, y_pred, average='macro')\n",
    "    res['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    if not y_true_val is None:\n",
    "        # this is useful when transfer learning is used with cross validation\n",
    "        res['accuracy_val'] = accuracy_score(y_true_val, y_pred_val)\n",
    "\n",
    "    res['recall'] = recall_score(y_true, y_pred, average='macro')\n",
    "    res['duration'] = duration\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_metrics \u001b[38;5;241m=\u001b[39m calculate_metrics(\u001b[43my_true\u001b[49m, y_pred, \u001b[38;5;241m0.0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "df_metrics = calculate_metrics(y_true, y_pred, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99
    },
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1670797392656,
     "user": {
      "displayName": "Mojtaba Askarzadeh Farahani",
      "userId": "02005001605152753874"
     },
     "user_tz": 300
    },
    "id": "BIeCbOs6e7o6",
    "outputId": "973650ee-67f0-43ae-cf19-3b4bf69641fc"
   },
   "outputs": [],
   "source": [
    "classifier.predict(X_test, y_true,X_train,y_train,y_test,return_df_metrics = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File('./Results/PHM2022_Multivar_Datasetbest_model.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_weights', 'optimizer_weights']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
