{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from joblib import parallel_backend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53785, 749, 3)\n",
      "(53785, 749, 1)\n"
     ]
    }
   ],
   "source": [
    "# define a list of datasets\n",
    "datasets = [\"PHM2022_Multivar\", \"PHM2022_Univar_PDIN\"]\n",
    "datasets_path = \"../datasets\"\n",
    "\n",
    "for dataset in datasets:\n",
    "    Dataset_name = dataset + \"_Dataset\"\n",
    "    Dataset = np.load(datasets_path + \"/\" + Dataset_name + \".npy\")\n",
    "    print(Dataset.shape)\n",
    "    \n",
    "\n",
    "    Labels_name = dataset + \"_Labels\"\n",
    "    Labels = np.load(datasets_path + \"/\"  + Labels_name + \".npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The dataset shape is:(53785, 749, 3)\n",
      "\n",
      " The number of data samples (N) is:53785\n",
      "\n",
      " The number of TS length (T) is:749\n",
      "\n",
      " The number of TS dimention (M) is:3\n",
      "KNN is not capable of doing classification on MTS. so it will be done on only the first dimension\n",
      "0.9525890118062657\n",
      "0.952625650419068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3914\n",
      "           1       0.76      0.80      0.78       636\n",
      "           2       0.99      0.98      0.99       678\n",
      "           3       0.97      0.97      0.97       583\n",
      "           4       1.00      1.00      1.00       651\n",
      "           5       0.83      0.79      0.81       639\n",
      "           6       1.00      1.00      1.00       607\n",
      "           7       0.92      0.98      0.95       603\n",
      "           8       0.97      0.92      0.94       645\n",
      "           9       1.00      1.00      1.00       628\n",
      "          10       0.92      0.88      0.90       523\n",
      "          11       0.89      0.93      0.91       650\n",
      "\n",
      "    accuracy                           0.95     10757\n",
      "   macro avg       0.94      0.94      0.94     10757\n",
      "weighted avg       0.95      0.95      0.95     10757\n",
      "\n",
      " fold 1 is Finished!\n",
      "0.9530538254160081\n",
      "0.9529114915044682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3940\n",
      "           1       0.76      0.79      0.78       619\n",
      "           2       0.99      1.00      0.99       678\n",
      "           3       0.95      0.98      0.97       647\n",
      "           4       1.00      1.00      1.00       591\n",
      "           5       0.84      0.77      0.80       616\n",
      "           6       1.00      0.99      0.99       590\n",
      "           7       0.93      0.97      0.95       612\n",
      "           8       0.96      0.92      0.94       629\n",
      "           9       1.00      1.00      1.00       610\n",
      "          10       0.93      0.88      0.90       558\n",
      "          11       0.90      0.93      0.91       667\n",
      "\n",
      "    accuracy                           0.95     10757\n",
      "   macro avg       0.94      0.94      0.94     10757\n",
      "weighted avg       0.95      0.95      0.95     10757\n",
      "\n",
      " fold 2 is Finished!\n",
      "0.9513804964209353\n",
      "0.9514796612571751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3861\n",
      "           1       0.77      0.81      0.79       657\n",
      "           2       0.98      0.99      0.99       719\n",
      "           3       0.97      0.97      0.97       619\n",
      "           4       1.00      1.00      1.00       586\n",
      "           5       0.82      0.78      0.80       622\n",
      "           6       1.00      0.99      0.99       608\n",
      "           7       0.93      0.96      0.94       662\n",
      "           8       0.95      0.91      0.93       622\n",
      "           9       1.00      1.00      1.00       628\n",
      "          10       0.93      0.90      0.92       550\n",
      "          11       0.88      0.93      0.91       623\n",
      "\n",
      "    accuracy                           0.95     10757\n",
      "   macro avg       0.94      0.94      0.94     10757\n",
      "weighted avg       0.95      0.95      0.95     10757\n",
      "\n",
      " fold 3 is Finished!\n",
      "0.9549130798549782\n",
      "0.9548377677021225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3884\n",
      "           1       0.80      0.82      0.81       677\n",
      "           2       0.99      0.99      0.99       697\n",
      "           3       0.96      0.98      0.97       613\n",
      "           4       1.00      1.00      1.00       693\n",
      "           5       0.83      0.79      0.81       599\n",
      "           6       0.99      0.99      0.99       625\n",
      "           7       0.92      0.97      0.94       635\n",
      "           8       0.96      0.90      0.93       595\n",
      "           9       1.00      1.00      1.00       577\n",
      "          10       0.94      0.88      0.91       521\n",
      "          11       0.89      0.94      0.92       641\n",
      "\n",
      "    accuracy                           0.95     10757\n",
      "   macro avg       0.94      0.94      0.94     10757\n",
      "weighted avg       0.96      0.95      0.95     10757\n",
      "\n",
      " fold 4 is Finished!\n",
      "0.9525890118062657\n",
      "0.9527365406839432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3981\n",
      "           1       0.76      0.81      0.78       594\n",
      "           2       0.99      0.99      0.99       720\n",
      "           3       0.97      0.96      0.97       608\n",
      "           4       1.00      1.00      1.00       580\n",
      "           5       0.82      0.79      0.80       598\n",
      "           6       0.99      0.99      0.99       628\n",
      "           7       0.92      0.96      0.94       642\n",
      "           8       0.96      0.91      0.93       628\n",
      "           9       1.00      1.00      1.00       614\n",
      "          10       0.92      0.87      0.89       539\n",
      "          11       0.89      0.92      0.90       625\n",
      "\n",
      "    accuracy                           0.95     10757\n",
      "   macro avg       0.93      0.93      0.93     10757\n",
      "weighted avg       0.95      0.95      0.95     10757\n",
      "\n",
      " fold 5 is Finished!\n",
      " Finished!\n",
      "Total time elapsed: 2494.4824s\n",
      "\n",
      " The dataset shape is:(53785, 749, 1)\n",
      "\n",
      " The number of data samples (N) is:53785\n",
      "\n",
      " The number of TS length (T) is:749\n",
      "\n",
      " The number of TS dimention (M) is:1\n",
      "0.9542623408013386\n",
      "0.954289549883318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3890\n",
      "           1       0.77      0.82      0.79       607\n",
      "           2       0.98      1.00      0.99       669\n",
      "           3       0.97      0.97      0.97       653\n",
      "           4       1.00      1.00      1.00       626\n",
      "           5       0.86      0.80      0.83       644\n",
      "           6       0.99      0.98      0.99       665\n",
      "           7       0.94      0.95      0.94       637\n",
      "           8       0.95      0.92      0.94       621\n",
      "           9       1.00      1.00      1.00       603\n",
      "          10       0.94      0.88      0.91       534\n",
      "          11       0.88      0.94      0.91       608\n",
      "\n",
      "    accuracy                           0.95     10757\n",
      "   macro avg       0.94      0.94      0.94     10757\n",
      "weighted avg       0.95      0.95      0.95     10757\n",
      "\n",
      " fold 1 is Finished!\n",
      "0.9557497443525147\n",
      "0.9556465685928506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3969\n",
      "           1       0.81      0.82      0.82       661\n",
      "           2       0.99      0.98      0.99       714\n",
      "           3       0.95      0.97      0.96       567\n",
      "           4       1.00      1.00      1.00       598\n",
      "           5       0.85      0.81      0.83       610\n",
      "           6       1.00      0.99      0.99       616\n",
      "           7       0.92      0.96      0.94       610\n",
      "           8       0.95      0.92      0.94       648\n",
      "           9       1.00      1.00      1.00       611\n",
      "          10       0.94      0.88      0.91       539\n",
      "          11       0.88      0.95      0.91       614\n",
      "\n",
      "    accuracy                           0.96     10757\n",
      "   macro avg       0.94      0.94      0.94     10757\n",
      "weighted avg       0.96      0.96      0.96     10757\n",
      "\n",
      " fold 2 is Finished!\n",
      "0.9517523473087292\n",
      "0.951768020577821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3922\n",
      "           1       0.76      0.79      0.78       633\n",
      "           2       0.99      0.99      0.99       681\n",
      "           3       0.96      0.96      0.96       612\n",
      "           4       1.00      1.00      1.00       626\n",
      "           5       0.82      0.80      0.81       631\n",
      "           6       1.00      0.99      0.99       578\n",
      "           7       0.91      0.98      0.95       632\n",
      "           8       0.98      0.91      0.94       642\n",
      "           9       1.00      1.00      1.00       586\n",
      "          10       0.91      0.88      0.90       547\n",
      "          11       0.90      0.92      0.91       667\n",
      "\n",
      "    accuracy                           0.95     10757\n",
      "   macro avg       0.94      0.93      0.93     10757\n",
      "weighted avg       0.95      0.95      0.95     10757\n",
      "\n",
      " fold 3 is Finished!\n",
      "0.9553778934647207\n",
      "0.955416735733105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3945\n",
      "           1       0.79      0.80      0.79       670\n",
      "           2       0.99      0.99      0.99       694\n",
      "           3       0.98      0.98      0.98       583\n",
      "           4       1.00      1.00      1.00       629\n",
      "           5       0.81      0.81      0.81       596\n",
      "           6       0.99      1.00      0.99       583\n",
      "           7       0.94      0.97      0.96       640\n",
      "           8       0.96      0.93      0.94       607\n",
      "           9       1.00      1.00      1.00       583\n",
      "          10       0.90      0.90      0.90       534\n",
      "          11       0.91      0.92      0.91       693\n",
      "\n",
      "    accuracy                           0.96     10757\n",
      "   macro avg       0.94      0.94      0.94     10757\n",
      "weighted avg       0.96      0.96      0.96     10757\n",
      "\n",
      " fold 4 is Finished!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9556567816305661\n",
      "0.955641095311139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3854\n",
      "           1       0.78      0.81      0.79       612\n",
      "           2       0.99      0.99      0.99       734\n",
      "           3       0.96      0.98      0.97       655\n",
      "           4       1.00      1.00      1.00       622\n",
      "           5       0.82      0.79      0.81       593\n",
      "           6       0.99      1.00      1.00       616\n",
      "           7       0.93      0.97      0.95       635\n",
      "           8       0.96      0.93      0.94       601\n",
      "           9       1.00      1.00      1.00       674\n",
      "          10       0.94      0.87      0.90       537\n",
      "          11       0.89      0.92      0.91       624\n",
      "\n",
      "    accuracy                           0.96     10757\n",
      "   macro avg       0.94      0.94      0.94     10757\n",
      "weighted avg       0.96      0.96      0.96     10757\n",
      "\n",
      " fold 5 is Finished!\n",
      " Finished!\n",
      "Total time elapsed: 2475.6630s\n"
     ]
    }
   ],
   "source": [
    "# change this directory for your machine\n",
    "root_dir = './'\n",
    "\n",
    "\n",
    "#add the classifier path to the sys\n",
    "#sys.path.append(\"./classifiers/\")\n",
    "\n",
    "# define a list of datasets\n",
    "#datasets = [\"PHM2022_Multivar\", \"PHM2022_Univar_PDIN\"]\n",
    "datasets_path = \"../datasets\"\n",
    "\n",
    "# define a list of algorithms\n",
    "#algorithms = [LR_module]\n",
    "algorirhms_path = \"./classifiers\"\n",
    "\n",
    "from classifiers import LR_module\n",
    "from classifiers import SVM_module\n",
    "from classifiers import RF_module\n",
    "from classifiers import NB_module\n",
    "from classifiers import TSKNN_module\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# perform cross-validation for each dataset and algorithm combination\n",
    "for dataset in datasets:\n",
    "    Dataset_name = dataset + \"_Dataset\"\n",
    "    Dataset = np.load(datasets_path + \"/\" + Dataset_name + \".npy\")\n",
    "    \n",
    "\n",
    "    Labels_name = dataset + \"_Labels\"\n",
    "    Labels = np.load(datasets_path + \"/\"  + Labels_name + \".npy\")\n",
    "\n",
    "    # Create a folder for results\n",
    "    results_path = root_dir + \"Results/\" + Dataset_name\n",
    "    if os.path.exists(results_path):\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            os.makedirs(results_path)\n",
    "        except:\n",
    "            # in case another machine created the path meanwhile !:(\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "    with parallel_backend('threading', n_jobs= 100):\n",
    "        #Run The Logistic Regression (LR) module\n",
    "        #LR_module.LR(results_path, Dataset_name, Dataset, Labels, nb_folds= n_folds, C=10)\n",
    "\n",
    "        #Run The Support Vector Machine (SVM) Module\n",
    "        #SVM_module.SVM(results_path, Dataset_name, Dataset, Labels, nb_folds= n_folds, C=10)\n",
    "\n",
    "        #Run The Random Forest (RF) Module\n",
    "        #RF_module.RF(results_path, Dataset_name, Dataset, Labels, nb_folds= n_folds, n_trees=500)\n",
    "\n",
    "        #Run The Naive Bayes (NB) Module\n",
    "        #NB_module.NB(results_path, Dataset_name, Dataset, Labels, nb_folds= n_folds)\n",
    "        \n",
    "        #Run The TSSKNN Module\n",
    "        TSKNN_module.KNN(results_path, Dataset_name, Dataset, Labels, dis= 'euclidean')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
